<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>LLM Probe</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      body {
        font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
          sans-serif;
        max-width: 800px;
        margin: 2rem auto;
        padding: 0 1rem 3rem;
        line-height: 1.5;
      }
      h1, h2, h3 {
        margin-top: 1.5rem;
      }
      code {
        background: #f4f4f4;
        padding: 0.1rem 0.3rem;
        border-radius: 3px;
        font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas,
          "Liberation Mono", "Courier New", monospace;
      }
      pre {
        background: #f4f4f4;
        padding: 0.75rem;
        border-radius: 4px;
        overflow-x: auto;
      }
      a {
        text-decoration: none;
      }
      a:hover {
        text-decoration: underline;
      }
      .file-list {
        margin: 0;
        padding-left: 1.2rem;
      }
      .badge {
        display: inline-block;
        padding: 0.1rem 0.4rem;
        border-radius: 999px;
        font-size: 0.75rem;
        background: #eee;
        margin-left: 0.4rem;
      }
    </style>
  </head>
  <body>
    <h1>LLM Probe (v1)</h1>
    <p>
      This is a public, static probe for testing large language models (LLMs)
      that claim to have web / GitHub access.
    </p>

    <h2>Raw file URLs</h2>
    <p>Replace <code>S3NTID3V</code> with your username and adjust the branch name if needed.</p>

    <ul class="file-list">
      <li>
        <strong>Instructions</strong>
        <span class="badge">start here</span><br />
        <code>
          https://raw.githubusercontent.com/S3NTID3V/llm-probe/main/instructions.md
        </code>
      </li>
      <li>
        <strong>Tests definition</strong><br />
        <code>
          https://raw.githubusercontent.com/S3NTID3V/llm-probe/main/tests.json
        </code>
      </li>
      <li>
        <strong>Result schema</strong><br />
        <code>
          https://raw.githubusercontent.com/S3NTID3V/llm-probe/main/result_schema.json
        </code>
      </li>
      <li>
        <strong>Secret phrase</strong><br />
        <code>
          https://raw.githubusercontent.com/S3NTID3V/llm-probe/main/secret.txt
        </code>
      </li>
    </ul>

    <h2>How to use with an LLM</h2>
    <ol>
      <li>
        In the LLM chat, paste the instructions URL, e.g.:<br />
        <code>
          https://raw.githubusercontent.com/S3NTID3V/llm-probe/main/instructions.md
        </code>
      </li>
      <li>
        Say something like:<br />
        <pre>
Please fetch and follow the instructions at:
https://raw.githubusercontent.com/S3NTID3V/llm-probe/main/instructions.md
and return the result.</pre>
      </li>
      <li>
        Save the JSON the model returns as a file, e.g.
        <code>results/gpt-5.1.json</code>, then use the compare script (below) to
        compare multiple models.
      </li>
    </ol>

    <h2>Repository files</h2>
    <ul class="file-list">
      <li><code>README.md</code> – overview and usage instructions.</li>
      <li><code>instructions.md</code> – what the model should follow.</li>
      <li><code>tests.json</code> – list of tasks for the model.</li>
      <li><code>result_schema.json</code> – structure of the model's JSON output.</li>
      <li><code>secret.txt</code> – contains the secret phrase used to verify HTTP access.</li>
      <li><code>compare_results.py</code> – local script for comparing JSON outputs.</li>
    </ul>

    <p>
      Edit <code>README.md</code>, <code>instructions.md</code>, and this
      <code>index.html</code> to replace the placeholder username and branch with your actual values.
    </p>
  </body>
</html>
